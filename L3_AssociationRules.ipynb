{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lily Williams DATA301 Lab 3.ipynb","provenance":[{"file_id":"1ZuVWsbDcDwx5TGcBOZxBYOjD1eWc0Zze","timestamp":1646018053368}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["****Lab 3: Association Rules (Recommendations)****\n","\n","Association Rules are frequently used for Market Basket Analysis (MBA) by retailers to understand the purchase behavior of their customers. This information can be then used for many different purposes such as recommendations, cross-selling and up-selling of products, sales promotions, loyalty programs, store design, discount plans and many others.\n","                    \n","Evaluation of item sets: Once you have found the frequent itemsets of a dataset, you need to choose a subset of them that are significant and interesting. Commonly used metrics for measuring significance and interest for selecting rules for recommendations are: \n","\n","Confidence, conf(I -> j) = support(I u j) / support(I)\n","\n","Interest, interest(I -> j) = conf(I -> j) - Pr[j]\n","\n","Application in product recommendations: The action or practice of selling additional products or services to existing customers is called cross-selling. Giving product recommendations is one of the examples of cross-selling that are frequently used by online retailers. One simple method to give product recommendations is to recommend products that are frequently browsed together by the customers. Suppose we want to recommend new products to the customer based on the products they have already browsed online. \n","\n"],"metadata":{"id":"kvJGaPtRnlyZ"}},{"cell_type":"markdown","source":["Note: You will need to download the browsing.txt file, you can use this in colab:"],"metadata":{"id":"xcK-16dkqlMt"}},{"cell_type":"code","source":["!gdown 'https://drive.google.com/uc?export=download&confirm=t&id=1Ijyh14a0Lh9sjwQUR6PE1TB2phjAZP4P'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_Lk-c_Wqk0N","executionInfo":{"status":"ok","timestamp":1647298918033,"user_tz":-780,"elapsed":1571,"user":{"displayName":"Lily Williams","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0zUTYWyTE4Z6l7yjmJ1b-t6PQTaBJw-HFhvx65w=s64","userId":"12000783581693855420"}},"outputId":"a8806096-74cf-41ba-d104-e4c09de5b1c6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?export=download&confirm=t&id=1Ijyh14a0Lh9sjwQUR6PE1TB2phjAZP4P\n","To: /content/browsing.txt\n","\r  0% 0.00/3.46M [00:00<?, ?B/s]\r100% 3.46M/3.46M [00:00<00:00, 165MB/s]\n"]}]},{"cell_type":"code","source":["# start the Spark context\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!pip install -q pyspark\n","\n","\n","import os\n","os.environ['PYTHONHASHSEED']=\"0\"\n","os.environ[\"PYSPARK_PYTHON\"]=\"python3\"\n","os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-8-openjdk-amd64/\"\n","# A few additional libraries we will need\n","from math import sqrt\n","\n","import pyspark\n","from pyspark import SparkConf, SparkContext\n","from pyspark.sql import *\n","\n","try:\n","  conf = SparkConf().setMaster(\"local[*]\").set(\"spark.executor.memory\", \"1g\").set(\"spark.executorEnv.PYTHONHASHSEED\",\"0\").set(\"spark.ui.port\", \"4050\")\n","  sc = SparkContext(conf = conf)\n","  spark = SparkSession.builder.getOrCreate()\n","except ValueError:\n","  #it's ok if the server is already started\n","  pass\n","\n","def dbg(x):\n","  \"\"\" A helper function to print debugging information on RDDs \"\"\"\n","  if isinstance(x, pyspark.RDD):\n","    print([(t[0], list(t[1]) if \n","            isinstance(t[1], pyspark.resultiterable.ResultIterable) else t[1])\n","           if isinstance(t, tuple) else t\n","           for t in x.take(100)])\n","  else:\n","    print(x)\n","    \n","\n","import unittest\n","Test = unittest.TestCase()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9bCiaksn6YC","executionInfo":{"status":"ok","timestamp":1647298991761,"user_tz":-780,"elapsed":73735,"user":{"displayName":"Lily Williams","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0zUTYWyTE4Z6l7yjmJ1b-t6PQTaBJw-HFhvx65w=s64","userId":"12000783581693855420"}},"outputId":"81fa1efe-e658-4952-dc11-ddc41aa19175"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n","\u001b[K     |████████████████████████████████| 198 kB 58.5 MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["# Question 1: Find products which are frequently browsed together\n","[45 points total]\n","\n","Write a Spark map-reduce program to find products which are frequently browsed together in the given browsing.txt. Each line represents a browsing session of a customer (a “basket”). On each line, each string of 8 characters represents the ID of an item browsed during that session. The items are separated by spaces. For example, this first line of browsing.txt:\n","\n","FRO11987 ELE17451 ELE89019 SNA90258 GRO99222 \n","\n","represents a browsing session (a “basket”) with 5 item IDs.\n"],"metadata":{"id":"QRtwcuMjqyAt"}},{"cell_type":"markdown","source":["## 1a) Naive All-Pairs\n","[15 points for correct top 5 most frequent pairs]\n","\n","Implement a naive Spark approach to finding frequest product pairs with support = 100 (i.e. product pairs need to occur together at least 100 times to be considered frequent):\n","\n","1. Create an RDD from the lines in the file\n","\n","2. Map each line into a list of all pairs of items in the basket. \n","\n","    Hint: this is an N^2 operation and can be done by writing a function with a nested loop that processes a single basket and then mapping this function over the RDD\n","\n","    Hint: you can ensure that a pair is counted regardless of whether it appears in a basket as …,A,...,B,... or …,B,...,A,... by outputting it as tuple(sorted((item1, item2))) which would output (A,B) for both cases\n","\n","3. Reduce the pairs into pair counts\n","\n","4. Take the top 5 most frequent pairs and display them, you should get:\n","\n","[(('DAI62779', 'ELE17451'), 1592), (('FRO40251', 'SNA80324'), 1412), (('DAI75645', 'FRO40251'), 1254), (('FRO40251', 'GRO85051'), 1213), (('DAI62779', 'GRO73461'), 1139)]\n"],"metadata":{"id":"w52djwGEq7gC"}},{"cell_type":"code","source":["def naive_allpairs(basket): ## Takes a single order\n","  item_list = basket.strip().split() ## Splits items into a list\n","  appears_together = []\n","  for i, item1 in enumerate(item_list): ## For each (i, item) pair\n","    for j, item2 in enumerate(item_list): ## Compare to each other (i, item) pair\n","      if i < j: ## ensure each pair is unique per basket\n","        appears_together.append(sorted((item1, item2))) ## Say there's a relationship and a basket of (A, B) = (B, A)\n","  return appears_together\n","\n","file = sc.textFile(\"browsing.txt\")\n","\n","baskets = file.flatMap(lambda line: naive_allpairs(line))\n","\n","mapped_baskets = baskets.map(lambda x: ((x[0], x[1]), 1))\n","reduced_baskets = mapped_baskets.reduceByKey(lambda a, b: a + b)\n","\n","dbg(reduced_baskets.takeOrdered(5, lambda x: -x[1]))\n","\n","## Takes 14 seconds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WK2wMMosq3qw","executionInfo":{"status":"ok","timestamp":1647302637936,"user_tz":-780,"elapsed":14652,"user":{"displayName":"Lily Williams","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0zUTYWyTE4Z6l7yjmJ1b-t6PQTaBJw-HFhvx65w=s64","userId":"12000783581693855420"}},"outputId":"e8e73276-106e-42fa-b358-757384c65e13"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[(('DAI62779', 'ELE17451'), 1592), (('FRO40251', 'SNA80324'), 1412), (('DAI75645', 'FRO40251'), 1254), (('FRO40251', 'GRO85051'), 1213), (('DAI62779', 'GRO73461'), 1139)]\n"]}]},{"cell_type":"markdown","source":["## 1b) A-Priori All-Pairs\n","[30 points total]\n","The naive approach can be slow and disk/memory intensive for large sets of browsing data. Improve this by applying the two step A-priori algorithm.\n","1. Create an RDD from the lines in the file\n","2. [15 points for correct top 5 most frequent items] Map each line into its items and then perform an item count on the entire RDD (this is step 1 of the A-priori algorithm). If you take the top 5 most frequent items you should get:\n","\n","  [('DAI62779', 6667), ('FRO40251', 3881), ('ELE17451', 3875), ('GRO73461', 3602), ('SNA80324', 3044)]\n","\n","3. Filter the frequent items and keep only those with >= 100 occurrences. Collect these as a map and broadcast this map to every Spark worker (see the Spark documentation for broadcast).\n","4. We can now begin Step 2 of the A-priori algorithm. This now follows the same as the naive algorithm except that when we map each line into a list of all pairs of items in the basket we first check to ensure that both items in the pair occur in the broadcast map from Step 1 of the A-priori algorithm. This significantly decreases the number of pairs that we output from this step.\n","5. Reduce the pairs into pair counts\n","6. [15 points for correct top 5 most frequent pairs] Take the top 5 most frequent pairs and display them, you should still get:\n","\n","  [(('DAI62779', 'ELE17451'), 1592), (('FRO40251', 'SNA80324'), 1412), (('DAI75645', 'FRO40251'), 1254), (('FRO40251', 'GRO85051'), 1213), (('DAI62779', 'GRO73461'), 1139)]\n"],"metadata":{"id":"1M5zAg1Ey1tg"}},{"cell_type":"code","source":["def priori_allpairs(basket): ## Takes a single order\n","  item_list = basket.strip().split() ## Splits items into a list\n","  appears_together = []\n","  for i, item1 in enumerate(item_list): ## For each (i, item) pair\n","    for j, item2 in enumerate(item_list): ## Compare to each other (i, item) pair\n","      if i < j and (item1 in broadcastedRDD.value and item2 in broadcastedRDD.value): ## ensure each pair is unique per basket and they're both in the most frequent items RDD\n","        appears_together.append(sorted((item1, item2))) ## Say there's a relationship and a basket of (A, B) = (B, A)\n","  return appears_together\n","\n","file = sc.textFile(\"browsing.txt\")\n","\n","### A-PRIORI STEP ONE ###\n","items = file.flatMap(lambda line: [(item, 1) for item in line.strip().split()])\n","item_freq = items.reduceByKey(lambda a, b: a + b)\n","\n","dbg(item_freq.takeOrdered(5, lambda x: -x[1]))\n","\n","most_freq = item_freq.filter(lambda x: x[1] >= 100).collectAsMap()\n","broadcastedRDD = sc.broadcast(most_freq)\n","### ###\n","\n","### A-PRIORI STEP TWO ###\n","baskets = file.flatMap(lambda line: priori_allpairs(line))\n","\n","mapped_baskets = baskets.map(lambda x: ((x[0], x[1]), 1))\n","reduced_baskets = mapped_baskets.reduceByKey(lambda a, b: a + b)\n","\n","dbg(reduced_baskets.takeOrdered(5, lambda x: -x[1]))\n","### ###\n","\n","## Takes 7 seconds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6E8IRAB0s-N0","executionInfo":{"status":"ok","timestamp":1647302660496,"user_tz":-780,"elapsed":8022,"user":{"displayName":"Lily Williams","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0zUTYWyTE4Z6l7yjmJ1b-t6PQTaBJw-HFhvx65w=s64","userId":"12000783581693855420"}},"outputId":"b17a7125-8b4d-4c56-f1e1-4b117aca6914"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["[('DAI62779', 6667), ('FRO40251', 3881), ('ELE17451', 3875), ('GRO73461', 3602), ('SNA80324', 3044)]\n","[(('DAI62779', 'ELE17451'), 1592), (('FRO40251', 'SNA80324'), 1412), (('DAI75645', 'FRO40251'), 1254), (('FRO40251', 'GRO85051'), 1213), (('DAI62779', 'GRO73461'), 1139)]\n"]}]},{"cell_type":"markdown","source":["# Question 2: Find interesting pair rules\n","[45 points: 15 for correct expressions for confidence score, 15 for correct expressions for interest score, 15 for ensuring the X->Y and Y->X rules are all computed so that the top 5 confidence and interesting rules are correct]\n"],"metadata":{"id":"DuTyFtqD5A2u"}},{"cell_type":"markdown","source":["## 2a) Compute Confidence Score\n","\n","Using the item pairs (X, Y) found in Part 1, compute the confidence score for the corresponding association rules X->Y and Y->X for each of them.\n","\n","Here are the top 5 confidence score rules:\n","\n","[(('DAI93865', 'FRO40251'), 1.0), (('GRO85051', 'FRO40251'), 0.9991762767710051), (('GRO38636', 'FRO40251'), 0.9906542056074765), (('ELE12951', 'FRO40251'), 0.9905660377358491), (('DAI88079', 'FRO40251'), 0.9867256637168142)]\n"],"metadata":{"id":"CVeEDcsz5Rg-"}},{"cell_type":"code","source":["# Using reduced_baskets for ((X, Y), n) tuples\n","# Using item_freq for (X, n) tuples\n","\n","def confidence(x, y, xy_freq):\n","  x_freq = broadcastedRDD.value[x]\n","  return ((x, y), xy_freq/x_freq)\n","\n","xy_confidence = reduced_baskets.map(lambda x: confidence(x[0][0], x[0][1], x[1]))\n","yx_confidence = reduced_baskets.map(lambda x: confidence(x[0][1], x[0][0], x[1]))\n","\n","confidence_scores = xy_confidence.union(yx_confidence)\n","dbg(confidence_scores.takeOrdered(5, lambda x: -x[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcUWOxs55eqw","executionInfo":{"status":"ok","timestamp":1647305415427,"user_tz":-780,"elapsed":2227,"user":{"displayName":"Lily Williams","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0zUTYWyTE4Z6l7yjmJ1b-t6PQTaBJw-HFhvx65w=s64","userId":"12000783581693855420"}},"outputId":"4c1e0329-4fa1-42c4-b34e-5faf2e087ad6"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[(('DAI93865', 'FRO40251'), 1.0), (('GRO85051', 'FRO40251'), 0.999176276771005), (('GRO38636', 'FRO40251'), 0.9906542056074766), (('ELE12951', 'FRO40251'), 0.9905660377358491), (('DAI88079', 'FRO40251'), 0.9867256637168141)]\n"]}]},{"cell_type":"markdown","source":["## 2b) Compute Interest Score\n","\n","Then compute the interest score for each of them. Report the top 5. You will need to use maps, joins, and lambda expressions. Here are the top 5 interesting rules:\n","\n","[(('DAI43868', 'SNA82528'), 0.9538739086342056), (('DAI93865', 'FRO40251'), 0.8752130156586605), (('GRO85051', 'FRO40251'), 0.8743892924296656), (('GRO38636', 'FRO40251'), 0.865867221266137), (('ELE12951', 'FRO40251'), 0.8657790533945096)]\n"],"metadata":{"id":"iojoW08F5Z8N"}},{"cell_type":"code","source":["def interest(x, y, confidence, total):\n","  # Interest(i -> J) = Confidence(i -> J) - Freq(J)/Total\n","  y_freq = broadcastedRDD.value[y]\n","  return((x, y), confidence - y_freq/total)\n","\n","total_baskets = file.count()\n","interestRDD = confidence_scores.map(lambda x: interest(x[0][0], x[0][1], x[1], total_baskets))\n","\n","\n","dbg(interestRDD.takeOrdered(5, lambda x: -x[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bv1ohqQ3_IiY","executionInfo":{"status":"ok","timestamp":1647305412048,"user_tz":-780,"elapsed":2346,"user":{"displayName":"Lily Williams","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0zUTYWyTE4Z6l7yjmJ1b-t6PQTaBJw-HFhvx65w=s64","userId":"12000783581693855420"}},"outputId":"fe7c0cba-0276-4dd6-d546-ee542865470b"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[(('DAI43868', 'SNA82528'), 0.9538739086342057), (('DAI93865', 'FRO40251'), 0.8752130156586605), (('GRO85051', 'FRO40251'), 0.8743892924296655), (('GRO38636', 'FRO40251'), 0.8658672212661371), (('ELE12951', 'FRO40251'), 0.8657790533945096)]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"ApG5QBktC_7z"},"execution_count":null,"outputs":[]}]}